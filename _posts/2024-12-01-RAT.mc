---
tags: LLM
---

# 伯克利实验室系列
## 检索器感知训练（RAT）：LLMs是在记忆还是在理解

预训练语言模型（LLMs）需要指令微调以更好地与人类激励相一致。这些方法在尝试为特定领域回答问题时，既提高了模型的行为又提高了准确性。然而，传统的指令微调在适应性、对上下文示例的依赖以及潜在的幻觉方面存在局限性。我们引入了“检索器感知训练”，这是一种有望解决这些挑战的新方法。让我们深入了解其细节。

## 传统指令调整的缺点
在其核心，指令调整允许LLMs根据提示中嵌入的特定指令生成响应。然而，这种方法有其局限性

- 适应性有限：传统的LLMs在面临信息实时变化或更新时可能会遇到困难。当使用不断发展的数据源，如 API 文档时，这尤其令人担忧。
- 依赖上下文学习：指令调整高度依赖上下文学习，这可能具有局限性。如果没有根据新数据或更新数据调整的能力，模型可能会产生过时或不准确的结果。
- 幻觉潜力：LLMs 的一大挑战是它们倾向于“幻觉”或生成错误或不相关的信息。传统的调谐方法已知会加剧这个问题。

## 拥抱 Retriever 感知训练
考虑到上述挑战，引入了检索器感知训练。这种方法背后的原理是为用户的提示添加额外的支持文档，例如：“使用此 API 文档进行参考：。”目标是教会LLM利用提供的支持文档（API 文档的引用）来生成对前半部分更全面的信息。这种方法的优势是多方面的：

- 适应性：该模型在测试时对 API 文档的变化变得更加适应。这意味着即使 API 发生变化，模型也可以参考最新的文档以提供准确的响应。
- 改进的上下文学习：通过参考外部文档，LLM可以超越其固有的知识，并从实时数据中提取信息，从而实现更准确和更新的响应。
- 幻觉减少：一个关键的好处是幻觉错误的减少。通过将响应建立在实时数据上，LLM产生虚假或不相关信息的机会降低。

## 一顿免费的午餐给 RAT？

然而，在现实中，对检索器感知训练的承诺尚未得到充分利用。这主要是因为检索器的准确性还不够高。换句话说，检索器的召回率已成为最终性能的瓶颈。想象一下，如果模型接收到的问题是“在伯克利查找”，但支持文件是“阿尔伯特·爱因斯坦的传记”，那么模型很容易就会混淆。因此，在检索器的召回率和更新LLMs的频率之间取得平衡是一个需要做出的选择。

总结与所有创新一样，检索器感知训练有其优点和缺点。但它的引入标志着朝着创建更适应性强、准确性高、错误率低的LLMs的令人兴奋的转变。随着我们继续完善这一方法，LLM训练的未来无疑充满了潜力。

